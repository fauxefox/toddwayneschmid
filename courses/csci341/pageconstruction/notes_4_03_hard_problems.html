<h1>Hard Problems</h1>

<p>
    Finding a resource-intensive solution so a problem is not evidence that the problem is difficult. 
    For example, the problem of sorting an array can be solved in various dumb ways: <a href="https://en.wikipedia.org/wiki/Bogosort" target="_blank">bogosort</a>, at one end, runs in \(\mathcal O(n!)\)-time, and merge sort at the other runs in \(\mathcal O(n\log(n))\)-time.
    Sorting ain't that bad!
</p>

<p>
    Big-O analysis of worst-case runtime is a sort of upper-bound on the difficulty of an algorithmic problem.
    Once we find an algorithm for solving a problem in \(\mathcal O(f)\)-time, we know that it is "at most \(\mathcal O(f)\)-difficult".
    This opens up the possibility of beating that time, thereby showing that the problem is not as hard as we thought.
</p>

<p>
    On the other hand, Big-\(\Omega\) analysis gives a lower bound on the (typically worst-case) running time of an algorithm. 
    But with Turing machines, complexity is a bit fuzzier: translating between a Turing machine and a physical computer is not always linear, and the Church-Turing thesis in particular does not directly make any observation about the complexity of translating between different versions of the deterministic Turing machine (like multi-tape and multiple-to-one-symbols; both of which take \(\mathcal O(n^2)\)-time).
    This fuzziness was our motivation to consider the families \(\mathsf{P}\), \(\mathsf{NP}\), \(\mathsf{EXP}\), and so on.
    In this lecture, our goal is to give a useful lower-bound on the complexity of an algorithm in this fuzzy paradigm of complexity classes.
</p>

<!--  -->
<h2>Hardness</h2>

<p>
    The intuitive notion of "one problem is harder than another", as many of you have probably discovered by now, has to do with reductions. 
    What we learn from a reduction \(L_1 \preceq L_2\) (i.e., there exists a reduction \(r \colon L_1 \preceq L_2\)) is that \(L_2\) was the "harder" problem: any solution to \(L_2\) is enough to solve the "easier" problem \(L_1\).
    This relation \(\preceq \subseteq 2^{A^*}\) is a kind of "relative hardness" measure for problems. 
    This is where the following terminology comes from.
</p>

<div class="definition">
    <b>(\(\mathsf{Fam}\)-Hardness)</b>
    Let \(\mathsf{Fam} \subseteq 2^{A^*}\) be any family of languages, and let \(L \subseteq A^*\) be a language. 
    We say that \(L\) is <i>\(\mathsf{Fam}\)-hard</i> if for any \(U \in \mathsf{Fam}\), there is a polynomial time reduction \(r \colon U \preceq L\).
</div>

<p>
    So, for example, a decision problem is <i>\(\mathsf{P}\)-hard</i> if it has a polynomial time reduction from every tractible problem.
    The broader class of \(\mathsf{NP}\)-hard problems get a special name because they are the prime focus of the \(\mathsf{P}=\mathsf{NP}\) problem mentioned last time.
</p>

<div class="definition">
    <b>(Hard Problems)</b>
    A decision problem (i.e., language) \(L \subseteq A^*\) is generally called <i>hard</i> if \(L\) is \(\mathsf{NP}\)-hard.
</div>

<p>
    A lot of your favourite problems are hard, unfortunately.
    Many puzzle and videogames have been shown to be \(\mathsf{NP}\)-hard, including 
    <ul>
        <li><a href="https://minesweepergame.com/math/minesweeper-is-np-complete-2018.pdf" target="_blank">Minesweeper</a></li>
        <li><a href="https://www.cs.ox.ac.uk/people/paul.goldberg/FCS/sudoku.html" target="_blank">Sudoku</a></li>
        <li><a href="https://ualberta.scholaris.ca/server/api/core/bitstreams/9031e952-751a-405c-bf3d-25bcf9b4f5d9/content" target="_blank">Sokoban</a></li>
        <li><a href="https://arxiv.org/pdf/2003.09914" target="_blank">Rush Hour</a></li>
        <li><a href="https://journals.sagepub.com/doi/10.3233/ICG-2004-27303" target="_blank">Battleship</a></li>
        <li><a href="https://theses.liacs.nl/pdf/2012-01JanvanRijn_2.pdf" target="_blank">Mahjong</a></li>
        <li>...(and many others)</li>
    </ul>
    What this means is that any algorithm for deciding whether a particular configuration of the puzzle (of arbitrary size---these results often generalize the game so that the game board can be arbitrarily large) has a solution <i>at all</i> can be used to solve any other computational problem in \(\mathsf{NP}\) with only a polynomial amount of added runtime.
</p>

<p>
    Directly showing that a decision problem is \(\mathsf{NP}\)-hard is so difficult that some of the most fundamental results of the field are proofs of this form.
    What is more typical is to show that a problem is \(\mathsf{NP}\)-hard by exhibiting a polynomial time reduction to another problem that is \(\mathsf{NP}\)-hard.
</p>

<div class="theorem">
    <b>(Hardness by Reduction)</b>
    Let \(\mathsf{Fam} \subseteq 2^{A^*}\) be a family of languages, and let \(L \subseteq A^*\) be \(\mathsf{Fam}\)-hard. 
    Suppose that we had another language \(W \subseteq A^*\) and a polynomial time reduction \(r \colon L \preceq W\).
    Show that \(W\) is also \(\mathsf{Fam}\)-hard.
</div>

<div class="problem">
    <b>(Proving Hardness by Reduction)</b>
    Prove the Hardness by Reduction theorem.
</div>

<p>
    We are going to see a reduction in action a little bit later.
</p>

<!--  -->
<h2>Completeness</h2>

<p>
    A slightly more confusing property of a problem with respect to a complexity class is <i>completeness</i>.
</p>

<div class="definition">
    <b>(\(\mathsf{Fam}\)-completeness)</b>
    Let \(\mathsf{Fam} \subseteq 2^{A^*}\) be a family of languages. 
    A language \(L \subseteq A^*\) is said to be <i>\(\mathsf{Fam}\)-complete</i> if \(L \in \mathsf{Fam}\) and \(L\) is \(\mathsf{Fam}\)-hard.
</div>

<p>
    <a href="https://www.cs.bme.hu/~friedl/alg/games.pdf" target="_blank">Many puzzle games, including some of those mentioned at the top</a>, are in fact \(\mathsf{NP}\)-complete, in addition to be \(\mathsf{NP}\)-hard.
    A long list of \(\mathsf{NP}\)-complete problems <a href="https://en.wikipedia.org/wiki/List_of_NP-complete_problems" target="_blank">can be found on Wikipedia</a>.
</p>

<div class="remark">
    One common misconception about \(\mathsf{NP}\)-complete problems is that they must have the most complex solutions imaginable: "if \(L \subseteq A^*\) is an \(\mathsf{NP}\)-complete decision problem that can be verified in \(\mathcal O(n^{5})\)-time, does that mean that there are no decision problems in \(\mathsf{NP}\) that require slower than \(\mathcal O(n^5)\)-time solutions?"
    The answer to this question is, of course, no.
    Completeness speaks of there being a polynomial-time reduction, and does not mention the runtime of that reduction: perhaps every reduction \(\mathcal S_y \colon U \preceq L\) from a given language \(U \subseteq A^*\) runs in \(\mathcal O(n^{17})\)-time. 
    Then the algorithm you obtain by composing the reduction with your verifier for \(L\) will run in \(\mathcal O(n^{17} + n^5) = \mathcal O(n^{17})\)-time as well.
</div>

<p>
    The significance of \(\mathsf{NP}\)-complete problems extends past their ubiquity in the gaming world. 
    Outside of the context of theory, many practical problems that we would love to be solved in some efficient manner are woefully \(\mathsf{NP}\)-complete.
    And what's worse, if anybody can come up with a polynomial time solution to any one of the many known \(\mathsf{NP}\)-complete problems, then that person has discovered that \(\mathsf{P} = \mathsf{NP}\) (an equation that is widely believed to be false).
</p>

<div class="theorem">
    <b>(The \(\mathsf{NP}\) to \(\mathsf{P}\) Pipeline)</b>
    Let \(L \subseteq A^*\) be a language, and assume that \(L\) is \(\mathsf{NP}\)-complete.
    If \(L \in \mathsf{P}\), then \(\mathsf{P} = \mathsf{NP}\).
</div>

<div class="proof">
    We already know that \(\mathsf{P} \subseteq \mathsf{NP}\).
    To see the opposite inclusion, let \(U \in \mathsf{NP}\) be any language verifiable in polynomial time. 
    Since \(L\) is \(\mathsf{NP}\)-hard, there is a polynomial time reduction \(U \preceq L\).
    By assumption, \(L \in \mathsf{P}\), so there is a polynomial time reduction from \(U\) to a tractable problem. 
    Thus, \(U \in \mathsf{P}\) as well.
</div>

<h2>Hard/Complete Problems</h2>

<p>
    We are now going to consider a few hard/complete problems.
    The first, and most important of these problems is the <i>satisfiability</i> problem.
    Most other \(\mathsf{NP}\)-complete problems are shown to be so by reducing the satisfiability problem to them.
</p>

<h3>Satisfiability</h3>

<p>
    In discrete math, you will have seen a bit of propositional logic.
    The basic ingredients were a set \(\mathbb P\) of <i>basic propositions</i>, and some <i>connectives</i> \(\wedge\) (and), \(\vee\) (or), and \(\neg\) (not) with which you could form new propositions (called <i>formulas</i>) from old ones. 
    More precisely, we can generate the set of formulas with a grammar.
</p>

<div class="definition">
    <b>(Propositional Formulas, Satisfiability)</b>
    Let \(\mathbb P\) be any set, elements of which we will call <i>basic propositions</i>.
    The set \(\mathit{Form}\) of all <i>propositional formulas</i> is generated by the grammar 
    \[
        F \to p \mid (F \wedge F) \mid (F \vee F) \mid (\neg F)
    \]
    where \(p \in \mathbb P\).

    <p></p>
    A <i>truth assignment</i> is a function \(\alpha \colon \mathbb P \to \{0,1\}\), indicating which basic propositions are to be taken as "false" or "true".
    The truth assignment \(\alpha\) extends to all propositional formulas via the truth table below: 
    \[\begin{array}{| c |c | c | c | c | c|}
        \hline
        \alpha(\varphi_1) & \alpha(\varphi_2) & \alpha(\varphi_1 \wedge \varphi_2) & \alpha(\varphi_1 \vee \varphi_2) & \alpha(\neg \varphi_1) \\
        \hline
        1 & 1 & 1 & 1 & 0 \\
        0 & 1 & 0 & 1 & 1 \\
        1 & 0 & 0 & 1 & 0 \\
        0 & 0 & 0 & 0 & 1 \\
        \hline
    \end{array}\]
    For a given formula \(\varphi\) and truth assignment \(\alpha \colon \mathbb P \to \{0,1\}\), we say that \(\alpha\) <i>satisfies</i> \(\varphi\) if \(\alpha(\varphi) = 1\).
    A formula \(\varphi\) is called <i>satisfiable</i> if there exists a truth assignment that satisfies it.
</div>

<p>
    As usual, we won't be writing all of the brackets into our propositional formulas.
    The order of operations for the connectives is:
    \[
        (\ ), ~ \neg, ~\wedge, ~\vee
    \]
    so for eg., \(\neg p \wedge q \vee r = (((\neg p) \wedge q) \vee r)\).
</p>

<div class="exercise">
    <b>(Satisfying Formula)</b>
    Determine which of the following formulas is satisfiable.
    <ol>
        <li>\(\neg p \wedge q \wedge \neg q\)</li>
        <li>\((p \vee q) \wedge (\neg q)\)</li>
        <li>\((p \wedge q) \vee (\neg q \wedge q) \vee (p \wedge \neg q)\)</li>
    </ol>
</div>

<p>
    The <i>satisfiability</i> problem is a decision problem involving propositional formulas in a certain format. 
</p>

<div class="definition">
    <b>(Conjunctive Normal Form)</b>
    A formula \(\varphi\) is a <i>literal</i> if \(\varphi = p\) or \(\varphi = \neg p\) for some \(p \in \mathbb P\).
    A <i>disjunction of literals</i> is a formula of the form 
    \[
        \varphi_1 \vee \varphi_2 \vee \cdots \vee \varphi_n
    \]
    where every \(\varphi_i\) is a literal.
    A formula is <i>in conjunctive normal form</i> (or <i>CNF</i>) if it is of the form 
    \[
        \varphi_1 \wedge \varphi_2 \wedge \cdots \wedge \varphi_n
    \]
    where this time, every \(\varphi_i\) is a disjunction of literals.
</div>

<p>
    Using DeMorgan's laws, one can show (by induction) that every propositional formula is logically equivalent to a formula in CNF.
    For a simple example, 
    \[\begin{aligned}
        \neg(p \wedge \neg q) \wedge \neg (q \vee r)
        = (\neg p \vee q) \wedge \neg q \wedge \neg r
    \end{aligned}\]
    The following problem, which Cook showed to be \(\mathsf{NP}\)-complete in 1971, deals with the complexity of determining whether a given propositional formula in CNF is satisfiable.
</p>

<div class="definition">
    <b>(Satisfiability)</b>
    The <i>satisfiability problem</i> is given by the language 
    \[
        \mathit{SAT} = \{\varphi \in \mathit{Form} \mid \text{\(\varphi\) is satisfiable and in CNF}\}
    \]
</div>

<p>
    It can be determined in linear time whether a given formula is in CNF (the string only has to be scanned from left to right once), so the real difficulty of the problem lies in finding a truth assignment that satifies the formula. 
    Note that given a formula in CNF, \(\varphi\), and given a truth assigment \(\alpha \colon \mathbb P \to \{0,1\}\), it can be determined in polynomial time whether \(\alpha\) satisfies \(\varphi\).
    Note that \(\varphi\) is by definition a string of symbols, so no string representation is needed here.
    Briefly, here is such a procedure: 

    <div><b>\(\alpha\)-SAT Checker Algorithm</b>
    <ol>
        <li>Scan \(\varphi\) from left to right and replace each instance of \(p\) with \(\alpha(p)\).  Move on to step 2.</li>
        <li>
            Now rewind the tape and scan from left to right and carry out the following replacements: 
            \[\begin{aligned}
                (1 \wedge 1) &\to 1 &
                (0 \wedge 1) &\to 0 \\
                (1 \wedge 0) &\to 0 &
                (0 \wedge 0) &\to 0 \\
                %
                (1 \vee 1) &\to 1 &
                (0 \vee 1) &\to 1 \\
                (1 \vee 0) &\to 1 &
                (0 \vee 0) &\to 0 \\
                %
                (\neg 1) &\to 0 &
                (\neg 0) &\to 1 
            \end{aligned}\]
        </li>
        <li>If the string on the tape consists of either \(0\) or \(1\), then halt. Else, go to 2.</li>
    </ol>
    </div>
    The length of the string decreases with every repetition of step 2, so this algorithm runs in \(\mathcal O(n^2)\)-time. 
    Observe, then, that the nondeterministic Turing machine that runs the above procedure on all possible truth assignments (for the basic propositions appearing in \(\varphi\)) runs in nondeterministic \(\mathcal O(n^2)\)-time.
</p>

<div class="lemma">
    <b>(SAT is NP)</b>
    The satisfiability problem is verifiable in polynomial time, i.e., \(\mathit{SAT} \in \mathsf{NP}\).
</div>

<div class="exercise">
    <b>(Satisfying Formulas Algorithmically)</b>
    Run the \(\alpha\)-SAT Checker algorithm above on the input string \((((\neg p) \vee q) \wedge ((\neg q) \wedge (\neg r)))\) and the truth assignment \(\alpha(p) = 1\), \(\alpha(q) = 0\), and \(\alpha(r) = 1\).
</div>

<p>
    Interestingly, all other problems in \(\mathsf{NP}\) can efficiently be reduced to \(\mathit{SAT}\).
</p>

<div class="theorem">
    <b>(Cook-Levin, 1971)</b>
    The satisfiability problem \(\mathit{SAT}\) is \(\mathsf{NP}\)-complete.
</div>

<p>
    The original proof can be found on page 2 of this paper: <a href="https://dl.acm.org/doi/pdf/10.1145/800157.805047" target="_blank">(Cook, 1971)</a>.
    Wikipedia has a <a href="https://en.wikipedia.org/wiki/Cook%E2%80%93Levin_theorem" target="_blank">great rendition of the proof</a>, reproducing an argument found in section 2.6 of <a href="https://archive.org/details/computersintract0000gare/page/n15/mode/2up" target="_blank">Computers and Intractability, Gary and Johnson</a>.
    The gist of the proof is that, given any general Turing machine that verifies a given language \(L\) in nondeterministic polynomial time, one can form disjunctions of literals that describe different aspects of the runtime of the Turing machine, and then satisfiability of the conjunction of those literals determines whether the Turing machine has an accepting run (the halting behaviour of the Turing machine can be deduced from the satisfiability of the conjunction of these formulas).
    All of this leads to a very important technique for proving that a given decision problem is \(\mathsf{NP}\)-hard.
</p>

<div class="theorem">
    <b>(Reduction to SAT)</b>
    Let \(L \subseteq A^*\) be any language (decision problem).
    If there is a polynomial time reduction \(\mathit{SAT} \preceq L\), then \(L\) is \(\mathsf{NP}\)-hard.
</div>

<p>
    In the same paper, Cook proves something even more remarkable: a much simpler version of \(\mathit{SAT}\) is also \(\mathsf{NP}\)-complete.
    This one we are actually going to prove by hand.
</p>

<div class="definition">
    <b>(3-Bounded Conjunctive Normal Form)</b>
    A <i>3-disjunct of literals</i> is a formula of the form 
    \[
        \varphi_1 \vee \varphi_2 \vee \varphi_3
    \]
    where every \(\varphi_i\) is a literal.
    A formula is <i>in 3-conjunctive normal form</i> (or <i>3-CNF</i>) if it is of the form 
    \[
        \varphi_1 \wedge \varphi_2 \wedge \cdots \wedge \varphi_n
    \]
    where this time, every \(\varphi_i\) is a 3-disjunct of literals.
</div>

<div class="theorem">
    <b>(3SAT is NP-complete)</b>
    The <i>3-conjunct satisfiability problem</i> is the decision problem 
    \[
        \mathit{3SAT} = \{\varphi \in \mathit{Form} \mid \text{\(\varphi\) is satisfiable and in 3-CNF}\}
    \]
    This problem is \(\mathsf{NP}\)-complete.
</div>

<div class="proof">
    First of all, \(\mathit{3SAT}\) is in \(\mathsf{NP}\) for the same reason that \(\mathit{SAT}\) is (the same algorithm works).
    For hardness, we are going to construct a polynomial time reduction \(r \colon \mathit{SAT} \preceq \mathit{3SAT}\).
    Then the Reduction to SAT theorem tells us that \(\mathit{3SAT}\) is \(\mathsf{NP}\)-hard.

    <p>
        The construction works by showing that every formula in CNF is equivalent to one in 3-CNF, and that the CNF-to-3-CNF conversion runs in polynomial time.
        We start with the following case to illustrate the process: consider the propositional formula 
        \[
            \varphi = p_1 \vee \neg p_2 \vee p_3 \vee \neg p_4
        \]
        for some \(p_1, \dots, p_4 \in \mathbb P\).
        Note that \(\varphi\) is satisfiable. 
        This formula is a disjunction of more than 3 literals, so is not in 3-CNF.
        But, since we have as many propositions as we want, we can find \({\color{blue} q_1},{\color{blue} q_2} \in \mathbb P\) that do not already appear in the formula, from which we can build the following formula that IS in CNF: 
        \[
            \varphi' = ({\color{blue} q} \vee p_1 \vee \neg p_2)
            \wedge ({\color{blue} \neg q} \vee p_3 \vee \neg p_4)
        \]
        The general idea is that \(\varphi'\) "partitions \(\varphi\) into possible ways of satisfying \(\varphi\)".
    </p>

    <div class="exercise">
        <b>(Simple 3SAT Transform)</b>
        Show that \(\varphi'\) is satisfiable.
        In fact, show that <i>any</i> truth assignment that satisfies \(\varphi\) also satisfies \(\varphi'\).
    </div>

    <p>
        Let's consider a slightly more complicated example:
        \[
            \varphi = (p_1 \vee \neg p_2 \vee p_3 \vee \neg p_4 \vee p_5) \wedge (\neg p_1 \vee p_2 \vee \neg p_4)
        \]
        This formula is in CNF but not in 3-CNF.
        The latter half of the formula is a disjunction of 3 literals, so it need not be changed. 
        The reducer we have in mind would transform (what is now) \(\varphi\) into 
        \[
            \varphi' = ({\color{blue} q_1} \vee p_1 \vee \neg p_2)
            \wedge ({\color{blue} q_2} \vee {\color{blue} \neg q_1} \vee p_3)
            \wedge ({\color{blue} \neg q_2} \vee p_4 \vee \neg p_5)
            \wedge (\neg p_1 \vee p_2 \vee \neg p_4)
        \]
    </p>

    <div class="exercise">
        <b>(Compund 3SAT Transform)</b>
        Consider the formula 
        \[
            \varphi = (p_1 \vee \neg p_2) \wedge (\neg p_1 \vee p_2 \vee \neg p_3 \vee p_4) \wedge \neg p_4 \wedge p_3
        \]
        <ol>
            <li>Is \(\varphi\) in 3-CNF? If not, use the technique above to find a formula \(\varphi'\) such that \(\varphi\) is satisfiable if and only if \(\varphi'\) is satisfiable.</li>
            <li>Is \(\varphi\) satisfiable?</li>
        </ol>
    </div>

    <p>
        In general, suppose 
        \[
            \varphi = \varphi_1 \wedge \varphi_2 \wedge \cdots \wedge \varphi_m
        \]
        where each \(\varphi_i\) is a disjunction of literals. 
        The polynomial time reducer moves from left to right, and finding a formula \(\varphi_i'\) in 3-CNF for each \(i \le m\) such that \(\varphi_i\) is satisfiable if and only if \(\varphi_i'\) is satisfiable. 
        The formula \(\varphi_i'\) is constructed as follows: 
        <ol>
            <li>
                if \(\varphi_i\) is a disjunction of at most 3 literals, \(\varphi_i' = \varphi_i\).
            </li>
            <li>
                Otherwise, if
                \[
                    \varphi_i = \ell_1 \vee \ell_2 \vee \cdots \vee \ell_k
                \]
                where \(\ell_j \in \{p_j, \neg p_j\}\) is a literal for each \(j \le k\) and \(k > 3\), we find basic propositions \({\color{blue} q_1},\dots, {\color{blue} q_{k-3}} \in \mathbb P\) that do not appear in \(\varphi\) or any of \(\varphi_1', \dots, \varphi_{i-1}'\) and define 
                \[
                    \varphi_i' = 
                    ({\color{blue} q_1} \vee \ell_1 \vee \ell_2)
                    \wedge ({\color{blue} \neg q_1} \vee {\color{blue} q_2} \vee \ell_3)
                    % \wedge ({\color{blue} \neg q_2} \vee {\color{blue} q_3} \vee \ell_4)
                    \wedge \cdots 
                    \wedge ({\color{blue} \neg q_{k-4}} \vee {\color{blue} q_{k-3}} \vee \ell_{k-2})
                    \wedge ({\color{blue} \neg q_{k-3}} \vee \ell_{k-1} \vee \ell_{k})
                \]
            </li>
        </ol>
        The string transformer \(r\) is then defined by
        \[
            r(\varphi) = \varphi' = \varphi_1' \wedge \varphi_2' \wedge \cdots \wedge \varphi_m'
        \]
        Notice that \(\varphi_i'\) is in 3-CNF, and therefore that \(\varphi'\) also is in 3-CNF.
    </p>

    <div class="individual-exercise">
        <b>(Complex 3-CNF Transform Correctness)</b>
        Show that \(\varphi\) is satisfiable if and only if \(\varphi'\) is satisfiable.
    </div>

    <p>
        We are now going to argue that \(r\) can be implemented by a Turing program that runs in \(\mathcal O(n^3)\)-time, where \(\mathsf{len}(\varphi) = n\).
        Let \(k = \max_{i \le n} \mathsf{len}(\varphi_i)\).
        Then the number of fresh propositions \(q_j\) added to \(\varphi\) is \(k-3\) (assuming \(k \ge 3\)).
        This tells us that \(\mathsf{len}(\varphi_i') \le (k-3) \times k\), and then \(\mathsf{len}(\varphi') \le m \times (k-3) \times k\). 
        We obviously have \(m \le n\) and \(k \le n\), so \(m \times k \le n^2\), and therefore \(\mathsf{len}(\varphi') \in \mathcal O(n^2)\).
        Thus, whatever the run-time of the implementation of \(r\), it needs to extend the formula \(\varphi\) with at most \(\mathcal O(n^2)\)-many characters.
        We need to argue that the process of implementing this extension adds at most another factor of \(n\) to the runtime.
        Here is the algorithm in more detail, running on \(\varphi\) (using multiple tapes if needed):
        <ol>
            <li>Scan the string \(\varphi\) and 
                <ol type="i">
                    <li>keep track of the largest number of literals that appear in a conjunct, call it \(k\)</li>
                    <li>if a conjunct \(\varphi_i\) has \( > 3\) literals, mark its first character</li>
                    <li>keep track of the basic propositions that appear.</li>
                </ol>
            </li>
            <li>
                If \(k > 3\), generate \(k-3\) fresh basic propositions, call them \(q_1, \dots, q_{k-3}\).
            </li>
            <li>
                For each \(\varphi_i\) with a marked first character, expand it according to the process described above.
            </li>
        </ol>
        Steps 1 and 2 take place in \(\mathcal O(n)\)-time.
        Step 3 is the time-intensive step:
        the expansion takes place \(\mathcal O(m)\) times, and splits a conjunct with \(k\) literals into \(\mathcal O(k^2)\) conjuncts. 
        In total, this step takes \(\mathcal O(m \times k^2) \subseteq \mathcal O(n^3)\) steps.
        Hence, in total, the algorithm to compute \(r\) takes \(\mathcal O(n + n + n^3) = \mathcal O(n^3)\)-time.
    </p>
    <p>
        Since \(\varphi\) is satisfiable if and only if \(r(\varphi) = \varphi'\) is satisfiable, \(r \colon \mathit{SAT} \preceq \mathit{3SAT}\).
        By the Reduction to SAT theorem, \(\mathit{3SAT}\) is \(\mathsf{NP}\)-hard.
    </p>
</div>

<p>
    And of course, we obtain the corresponding technique for showing that a decision problem is \(\mathsf{NP}\)-hard.
</p>

<div class="theorem">
    <b>(Reduction to 3SAT)</b>
    Let \(L \subseteq A^*\) be any language (decision problem).
    If there is a polynomial time reduction \(\mathit{3SAT} \preceq L\), then \(L\) is \(\mathsf{NP}\)-hard.
</div>

<p>
    Many, many problems known to be \(\mathsf{NP}\)-hard/complete are proven to be so by reduction from \(\mathit{3SAT}\), because it is so simple to work with.
</p>

<div class="example">
    <b>(independent set Problem)</b>
    Recall that a <i>(undirected) graph</i> is a pair \(\mathcal G = (V, E)\) consisting of a set \(V\) of <i>vertices</i> and a set \(E \subseteq \big\{ \{x,y\} \mid \text{\(x,y \in V\) and \(x \neq y\)}\big\}\) of <i>edges</i>.
    We write \(x \smile y\) when \(\{x,y\} \in E\) and say that \(x\) and \(y\) are <i>related</i>, and otherwise write \(x \not\smile y\).

    <div class="definition">
        <b>(Independent Set)</b>
        An <i>independent set</i> of a graph \(\mathcal G = (V, E)\) is a subset \(C \subseteq V\) such that for every \(x,y \in C\), \(x \not\smile y\).
        An <i>independent set of size \(k\)</i> is just a independent set \(C\) with size \(|C| = k\).

        <p>
            Let \(\mathbf G\) be the set of all undirected finite graphs.
            The <i>independent set problem (for size \(k\))</i> is the decision problem 
            \[
                \mathit{ISet} = \{(\mathcal G, k) \in \mathbf{G} \times \mathbb N \mid \text{\(\mathcal G\) has a independent set of size \(k\)}\}
            \]
        </p>
    </div>

    It turns out that the independent set problem is \(\mathsf{NP}\)-complete, which we can verify with a polynomial time reduction \(r \colon \mathit{3SAT} \preceq \mathit{ISet}\).

    <p>
        OK, so what do we need to do? 
        We need to come up with a way of transforming a 3-CNF formula \(\varphi\) into an undirected graph \(\mathcal G\) and a natural number \(k\) such that \(\mathcal G\) has a independent set of size \(k\) if and only if \(\varphi\) is satisfiable. 
        Here is the transformation (based on <a href="https://www.cs.umd.edu/class/spring2025/cmsc451-0101/Lects/lect17-np-3sat-is.pdf" target="_blank">this set of notes</a>): 
        <div>
            <b>(3-CNF to Graph Transformation)</b><br>
            Start with a 3-CNF formula 
            \[
                \varphi = 
                (\ell_{11} \vee \ell_{12} \vee \ell_{13}) \wedge 
                \cdots 
                \wedge (\ell_{m1} \vee \ell_{m2} \vee \ell_{m3}) 
            \]
            we define a graph \(r(\varphi) = \mathcal G = (V, E)\) as follows:
            <ol>
                <li>
                    Start by removing repeated literals and tautologies from \(\varphi\):
                    <ol type="i">
                        <li>if a conjunct \(\varphi_i\) contains two instances of a literal \(\ell\), remove one of them</li>
                        <li>if a conjunct \(\varphi_i\) contains both \(p\) and \(\neg p\) for some \(p \in \mathbb P\), replace \(\varphi_i\) with a fresh basic proposition \(q\)</li>
                        <li>if there is a proposition \(p\) (or \(\neg p\)) in \(\varphi\) such that no instance of \(\neg p\) (resp., \(p\)) appears in \(\varphi\), then replace every conjunct \(\varphi_i\) in \(\varphi\) in which \(p\) appears (resp., \(\neg p\)) with a fresh basic proposition \(q\).</li>
                    </ol>
                    This step prepares the formula to be represented as a graph, and does not affect whether or not it is satisfiable.
                </li>
                <li>The vertices of \(\mathcal G\) are all the literals that appear in (the newly constructed) \(\varphi\), in their respective conjuncts, 
                    \[
                        V = \{(j, \ell_{ji}) \in \mathbb P\mid 1 \le j \le m, 1 \le i \le 3\}
                    \]
                    Here, the \(j\) indicates the \(\varphi_j\) in which \(\ell_{ij}\) appears.
                </li>
                <li>
                    The edges are of two kinds: 
                    \[\begin{aligned}
                        E &= \{(j, \ell_{j1}) \smile (j, \ell_{j2}) \smile (j, \ell_{j3}) \smile (j, \ell_1) \mid 1 \le j \le m\}\\
                        &\qquad \cup~\{(j, \ell_{ji}) \smile (l, \ell_{lk}) \mid j \neq l, \ell_{ji} = \neg \ell_{jk}\}
                    \end{aligned}\]
                    In other words, the disjunctions of literals are all connected as triangles, and across these triangles and two literals that are each other's negation are connected.
                </li>
                <li>
                    The number \(k\) of independent vertices will be \(k = m\), to force one vertex to be in every triangle in any independent set.
                </li>
            </ol>

            <p>
                For example, the formula 
                \[
                    \varphi = (\neg p \vee \neg q \vee r) \wedge (q \vee \neg r \vee s) \wedge (p \vee \neg s)
                \]
                gets put together as the graph below:
                <img src="../imgs/drawing_formulas.svg" />
            </p>

            <div class="exercise">
                <b>(Drawing Formulas)</b>
                Draw \(r(\varphi)\) for each of
                <ol>
                    <li>\(({\color{blue} q} \vee p_1 \vee \neg p_2) \wedge ({\color{blue} \neg q} \vee p_3 \vee \neg p_4)\)</li>
                    <li>\(({\color{blue} q_1} \vee p_1 \vee \neg p_2)
                        \wedge ({\color{blue} q_2} \vee {\color{blue} \neg q_1} \vee p_3)
                        \wedge ({\color{blue} \neg q_2} \vee p_4 \vee \neg p_5)
                        \wedge (\neg p_1 \vee p_2 \vee \neg p_4)\)</li>
                </ol>
            </div>

            <p>
                Let \(\varphi\) be the transformed formula, after Step 1 above has occurred.
                Then the existence of an independent set of size \(k = m\) indicates an assignment of truth values to propositions that satisfies the formula.
                For example, in the formula \(\varphi\) before the Drawing Formulas exercise above and its graph, the vertices \((1, \neg p), (2, \neg r), (3, \neg s)\) form an independent set. 
                <img src="../imgs/drawing_formulas_sat.svg" />
                We obtain a truth-assignment that satisfies \(\varphi\) from this by setting \(\alpha(p) = \alpha(r) = \alpha(s) = 0\).
                
            </p>
            <p>
                More generally, we have the following: let \(\varphi = (\ell_{11} \vee \ell_{12} \vee \ell_{13}) \wedge \cdots \wedge (\ell_{m1} \vee \ell_{m2} \vee \ell_{m3})\), assume that Step 1 of the algorithm above has already taken place, and let \(\mathcal G = (V, E)\) be the graph obtained from \(\varphi\).
                <ul>
                    <li>
                        To obtain a truth assignment from an independent set, let \(S \subseteq V\) be an independent set of size \(m\). 
                        Since \(S\) is an independent set, at most one element of \(S\) appears in each triangle.
                        And furthermore, since \(S\) has \(m\) elements, there is exactly one element of \(S\) in each triangle.
                        Moreover, for each \(p_{ij} \in \mathbb P\), 
                        Define \(\alpha_S \colon \mathbb P \to \{0,1\}\) by 
                        \[
                            \alpha_S(p) = \begin{cases}
                                1 & (p, j) \in S \text{ for some } j \le m\\
                                0 & (\neg p, j) \in S \text{ for some } j \le m
                            \end{cases}
                        \]
                        define \(\alpha_S(q) = 0\) for all other \(q\) appearing in \(\varphi\) that does not appear in any vertex in the indpendent set \(S\).
                        This is a truth assignment that satisfies \(\varphi\) because every conjunct of \(\varphi\) contains a literal \(\ell\) such that \(\alpha(\ell) = 1\).
                    </li>
                    <li>
                        To obtain an independent set from a truth assignment \(\alpha\) that satisfies \(\varphi\), for each conjunct \(\varphi_j\) of \(\varphi\), choose a vertex \((j, \ell_{ji}) \in V\)  such that \(\alpha(\ell_{ji}) = 1\) and form a set \(S\) from those choices. 
                        There exists such a node in each conjunct because \(\alpha(\varphi_j) = 1\) for all \(j\). 
                        This set is of size \(m\) by design.
                        This set \(S\) is an independent set because we have chosen exactly one vertex from each triangle, and because only one of each pair of vertices of the form \((j, p)\) and \((l, \neg p)\) that can appear in \(S\) (because \(\alpha\) is a function).
                    </li>
                </ul>
                Hence, \(\varphi\) is satisfiable if and only if \(r(\varphi) = \mathcal G = (V, E)\) has an independent set of size \(m\).
            </p>

            <p>
                The string transformer \(r\) is computed according to the algorithm described above. 
                Step 1 can be taken in \(\mathcal O(n^2)\)-time, since it involves traversing the formula at most \(n\) times. 
                The graph \(r(\varphi)\) can be computed in \(\mathcal O(n^2)\) time by traversing the formula \(\varphi\) once for each connection formed.
                This shows that \(r \colon \mathit{3SAT} \preceq \mathit{ISet}\) in polynomial time. 
                By the Reduction to 3SAT theorem, \(\mathit{ISet}\) is \(\mathsf{NP}\)-hard.
            </p>
            
            <div class="exercise">
                <b>(Completeness, Now)</b>
                Show that \(\mathit{ISet} \in \mathsf{NP}\).
                <div class="hint">
                    Guess all the sets!
                </div>
            </div>
        </div>
    </p>
</div>

<!--  -->
<!-- <h3>The Travelling Salesman Problem</h3>

<p>
    A <i>weighted directed graph</i> is a pair \(\mathcal G = (X, \to)\) consisting of a set \(X\) of \emph{nodes} and a relation \({\to} \subseteq X \times \mathbb N \times X\) of \emph{weighted edges}.
    Given nodes \(x,y \in X\), the <i>cost of travel along a path</i> 
    \[
        P = (x \xrightarrow{c_1} x_1 \xrightarrow{c_2} \cdots \xrightarrow{c_n} x_n = y)
    \] 
    is the sum \(\mathsf{cost}(P) = \sum_{i = 1}^n c_i\).
    A <i>tour</i> of a (weighted) directed graph is a path 
    \[
        T = (x_0 \xrightarrow{c_1} x_1 \xrightarrow{c_2} x_2 \xrightarrow{c_3} \cdots \xrightarrow{c_n})
    \]
    such that \(X = \{x_0, x_1, \dots, x_n\}\).
</p>

<div class="definition">
    <b>(Travelling Salesman Decision Problem)</b>
    The <i>travelling salesman decision problem</i> is the decision problem 
    \[
        \mathit{TSDP} = \{(\mathcal G, k) \mid \text{there exists a tour \(T\) of \(\mathcal G\) with \(\mathsf{cost}(T) \le k\)}\}
    \]
</div>

<p>
    The travelling salesman decision problem is known to be \(\mathsf{NP}\)-complete.
</p>

<div class="theorem">
    <b>(TSDP is NP-complete)</b>
    The travelling salesman decision problem is \(\mathsf{NP}\)-complete.
</div>

<p>
    The proof of hardness is somewhat beyond us for now, but I'm sure you can figure out the completeness.
</p>

<div class="exercise">
    <b>(TSDP is NP)</b>
    Show that the travelling salesman decision problem is in \(\mathsf{NP}\).
</div> -->
