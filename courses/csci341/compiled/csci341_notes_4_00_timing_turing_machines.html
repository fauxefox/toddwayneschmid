<!-- THIS IS A COMPILED FILE 
 Compiled on 2025-11-12 -->



































































































<!DOCTYPE html>

<head>
	
	<meta charset="UTF-8">
	<meta name="author" content="Todd Schmid">
	
	<!-- Renders latex formulas -->
	<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
	<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    
	<!-- Renders tikz figures mid page -->
    <link rel="stylesheet" type="text/css" href="https://tikzjax.com/v1/fonts.css">
    <script src="https://tikzjax.com/v1/tikzjax.js"></script>
	
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	
	<link rel="stylesheet" href="../../../styles.css" />
	<link rel="stylesheet" href="../../course_styles.css" />
	<link rel="icon" href="../../../squidab.png" />
	
	<!-- * Customize for each course * -->
	<title>CSCI 341 Theory of Computation</title>
	<meta name="description" content="Course pages for CSCI 341.">
	<meta name="keywords" content="bucknell,theory,computer,science,schmid,csci341">
	<!-- ***************************** -->
</head>

<body>

<div id="content">

<!-- Header Section -->
<div id="course_head" style="text-align: left;">
	<h1 style="margin-bottom: 0; text-align: left;">CSCI 341 Theory of Computation</h1>
	<i>Fall 2025, with <a href="../../../teaching.html">Schmid</a></i>
	<div id="links">
		<!-- * Customize for each course * -->
		<a href="csci341_index.html"><span class="link">Syllabus</span></a>
		<a href="csci341_contents.html"><span class="link">Notes</span></a>
		<a href="csci341_resources.html"><span class="link">Resources</span></a>
		<a href= "csci341_assignments.html"><span class="link">Assignments</span></a>
		<!-- ***************************** -->
	</div>
</div>



<div id="stuff">


<!-- BEGINNING OF BODY -->
<div style="border: none; margin-bottom: -20px; padding: 0px; text-align: center;"><a href="../compiled/csci341_notes_3_08_recognizability_and_enumerability.html"><span class="link" style="width:40%"> &larr; 3.8 Recognizability And Enumerability</span></a></div><h1>Timing Turing Machines</h1>

<p>
    In the previous part of the course, we discovered the <i>Turing machine</i>, a powerful model of computation that mimics the bit-writing-and-rewriting operations of modern hardware.
    It was a mathematical model of computation, which allowed us to give an "upper-bound" on the power of computing as a whole: it showed us that there are computational problems that <i>cannot be solved algorithmically</i>.
</p>

<p>
    But what about the problems that <i>can</i> be solved algorithmically?
    We are now ready for Part 4 of this story, which has less to do with whether or not a given computational problem <i>can be solved at all</i>, and more to do with <i>how many resources it takes to solve the problem</i>.
    This is what's known as the <i>complexity</i> of the problem.
    Studying complexity with Tureing machines precisely requires precise definitions of <i>time</i> and <i>space</i> as resources.
</p>

<h2>Runtime</h2>

<p>
    Our model for the memory of a computer was the <i>tape machine</i>, which we defined to be a pair \((t, i)\) consisting of a <i>tape</i> \(t \colon \mathbb Z \to A \cup \{\_\}\)  and a <i>position</i> \(i \in \mathbb Z\).
    Tape machines came with a notion of <i>tape program</i>, and we defined these with a grammar that allowed us to write sequences of the basic commands \(\mathtt{move~right}\), \(\mathtt{move~left}\), and \(\mathtt{write~\sigma}\), where \(\sigma \in A\).
    Now, it is a bit hard to say how much time each of these basic commands takes to run, given they are abstract entities.
    In particular, we don't know the <i>units</i> of time to measure with. 
    Our fundamental assumption going forward is that <i>each of these basic tape machine commands takes about the same amount of time to run</i>.
    This allows us to use the amount of time that a basic tape machine command to run <i>as our unit of time</i>.
    This reduces measuring the time taken by a particular tape program to simply counting the number of basic tape machine commands get run.
</p>

<div class="definition">
    <b>(Tape Program Runtime)</b>
    Let \(p \in \mathtt{Tape}\) be a tape machine program. 
    Then the <i>runtime of \(p\)</i>, written \(\mathsf{rtime}(p)\), is the number of basic tape machine commands that appear in \(p\).
    More formally, 
    <ol>
        <li>\(\mathsf{rtime}(\mathtt{skip}) = 0\)</li>
        <li>\(\mathsf{rtime}(\mathtt{move~left}) = \mathsf{rtime}(\mathtt{move~left}) = \mathsf{rtime}(\mathtt{move~right}) = 1\)</li>
        <li>If \(p,q \in \mathtt{Tape}\), then \(\mathsf{rtime}(p{.}q) = \mathsf{rtime}(p) + \mathsf{rtime}(q)\)</li>
    </ol>
</div>

<p>
    The definition of running time for tape programs extends pretty readily to timing Turing machine programs, with the minute exception that we now have to deal with the possibility that a particular Turing machine program does not halt. 
</p>

<div class="definition">
    <b>(Turing Program Runtime)</b>
    Let \(\mathcal T = (Q, A, \delta)\) be a Turing machine.
    The <i>runtime</i> of a given a path through the Turing machine 
    \[
        x_0 \xrightarrow{a_1 \mid p_1} x_1 \xrightarrow{a_2 \mid p_2} \cdots \xrightarrow{a_n \mid p_n} x_n
        \qquad\qquad (*)
    \]
    is the nonnegative integer \(\mathsf{rtime}(p_1{.}p_2\dots p_n)\).
    If the path (*) is a halting run in \(\mathcal T\) starting from \(x\) on an input word \(w\), then we say that the runtime of (*) is <i>completed</i>.
    If it is a run but is not halting, then we say that it is <i>partial</i>.

    <p></p>
    If we additionally assume that \(\mathcal T\) is deterministic and \(x\) halts on input \(w\), then we define 
    \[
        \mathsf{rtime}(\mathcal T, x)(w) = \mathsf{rtime}(p_1{.}p_2 \dots p_n)
    \]
    if (*) is a halting run, and say that \(\mathsf{rtime}(\mathcal T, x)(w)\) is the <i>runtime of \(x\) on input \(w\)</i>.
</div>

<p>
    Later, we will define the runtime of a Turing program where the Turing machine is potentially nondeterministic.
    But for now, we assume determinism.
</p>

<p>For the sake of a snappier notation, we will often write \(\mathsf{rtime}(x)(w)\) instead of \(\mathsf{rtime}(\mathcal T, x)(w)\) if \(\mathcal T\) is understood from context.</p>

<div class="exercise">
    <b>(Counting Steps)</b>
    Determine the runtimes of the following Turing program, \(x_{clr}\) in the figure below, on each input.
    <img src="../imgs/x_clr.svg" />
    <ol>
        <li>\(\mathsf{rtime}(x_{clr})(\varepsilon)\)</li>
        <li>\(\mathsf{rtime}(x_{clr})(0)\)</li>
        <li>\(\mathsf{rtime}(x_{clr})(010)\)</li>
    </ol>
</div>

<p>
    Now, usually when we are measuring the runtime of an algorithm, we are concerned with one of three measures of runtime complexity: <i>worst-case</i>, <i>best-case</i>, and <i>average-case</i> (there is also amortized analysis, but this is a more complex issue for Turing machines) runtimes on inputs of a given size.
    Measuring size-of-input is straightforward for Turing programs; it's the length of the input word.
    Best-case and average-case analyses also make sense for Turing programs, but we are going to focus on worst-case analysis for this course for the sake of simply illustrating how analyzing Turing programs is generally done.
    The worst-case runtime of a Turing program is simply the maximum runtime over all inputs of a given size.
</p>

<div class="definition">
    <b>(Worst-case Runtime)</b>
    Let \(\mathcal T = (Q, A, \delta)\) be a Turing machine, let \(x \in Q\), and let \(n \in \mathbb N\).
    The <i>worst-case runtime of \(x\) on inputs of length \(n\)</i>, if it exists, is the number 
    \[
        \mathsf{rtime}_x(n) = \max \{ \mathsf{rtime}(x)(w) \mid w \in A^* \text{ where } \mathsf{len}(w) \le n\}
    \]
    if it exists, and we write \(\mathsf{rtime}_x(n) = \infty\) if \(x\) runs forever on some input \(w\) with \(\mathsf{len}(w) \le n\).
</div>

<div class="exercise">
    <b>(Counting worst-case Steps)</b>
    Determine the worst-case runtimes of the following Turing program, \(x_{clr}\) in the figure below.
    <img src="../imgs/x_clr.svg" />
    <ol>
        <li>\(\mathsf{rtime}_{x_{clr}}(0)\)</li>
        <li>\(\mathsf{rtime}_{x_{clr}}(2)\)</li>
        <li>\(\mathsf{rtime}(x_{clr})(4)\)</li>
    </ol>
</div>

<p>
    If \(x\) halts on all inputs, then the \(\cup \{\infty\}\) is unnecessary in the definition above.
</p>

<h3>Runtime Complexity</h3>

<p>
    The worst-case runtime of a Turing program \(x\), as long as it halts on all inputs, is therefore a function on the natural numbers, 
    \[
        \mathsf{rtime}_x \colon \mathbb N \to \mathbb N
    \]
    This allows us to apply tools for <i>asymptotic comparisons</i> between worst-case runtimes, which you have already seen in past courses.
    We include the relevant definitions below anyhow, for reference.
</p>

<div class="definition">
    <i>(Asymptotic Comparison)</i>
    Let \(f, g \colon \mathbb N \to \mathbb N\) be any two functions from the natural numbers to the natural numbers.
    <ul>
        <li>We write \(f \in \mathcal O(g)\) and say that \(f\) <i>\(g\) grows as fast as \(f\)</i> if there is a \(c > 0\) such that for all \(n \in \mathbb N\), \(f(n) < c ~ g(n)\).</li>
        <li>We write \(g \in \Omega(f)\) if \(f \in \mathcal O(g)\)</li>
        <li>We write \(f \approx g\) and say that <i>\(f\) and \(g\) grow at the same rate</i> if \(f \in \mathcal O(g)\) and \(f \in \Omega(g)\)</li>
    </ul>
</div><div style="border: none; margin-bottom: -20px; padding: 0px; text-align: center;"><a href="../compiled/csci341_notes_3_08_recognizability_and_enumerability.html"><span class="link" style="width:40%"> &larr; 3.8 Recognizability And Enumerability</span></a></div>


<!-- END OF BODY -->
    <div style="height: 50px;border-top: 1px solid rgb(131, 131, 131);margin-top: 50px; padding: 20px; text-align: right;">
        <a href=""><span class="link">Top</span></a>
    </div>
</div>
</div>
</body>


</html>